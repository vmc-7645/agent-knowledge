"""agent_runner.py – minimal Weave CLI agent\n--------------------------------------------------\n* Embeddings handled by FastAPI server endpoints (client passes empty list).\n* LLM (OpenAI) handled client-side.\n* Interactive terminal chat.\n* Uses memory.py helper functions to persist Q/A.\n"""

import os
import sys
import asyncio
import weave
import openai

# Import async memory helpers generated by the user
from agent import memory  # assumes memory.py lives in agent/ __init__.py not required

from dotenv import load_dotenv

# --------------------------------------------------
# ENVIRONMENT
# --------------------------------------------------
load_dotenv()
WEAVE_PROJECT = os.getenv("WEAVE_PROJECT", "wandbhackathon")
openai.api_key = os.getenv("OPENAI_API_KEY")

# Initialise Weave (logs all @op calls)
weave.init(WEAVE_PROJECT)

# --------------------------------------------------
# LLM Agent – single op
# --------------------------------------------------
@weave.op()
def ask_llm(prompt: str) -> str:
    """Single GPT-4 call wrapped for observability."""
    response = openai.ChatCompletion.create(
        model="gpt-4o-mini",  # swap as needed
        messages=[{"role": "user", "content": prompt}],
    )
    return response["choices"][0]["message"]["content"].strip()


# --------------------------------------------------
# CLI LOOP
# --------------------------------------------------
async def chat():
    print("Type 'exit' to quit.")
    while True:
        try:
            user_input = input("You > ")
        except (KeyboardInterrupt, EOFError):
            print()
            break

        if user_input.lower() in {"exit", "quit"}:
            break

        # Weave-tracked LLM call
        answer = ask_llm(user_input)
        print(f"Agent > {answer}\n")

        # Persist memory (embedding handled server-side -> pass [])
        try:
            await asyncio.gather(
                memory.remember_question(user_input, []),
                memory.remember_answer(answer, []),
            )
        except Exception as e:  # noqa: BLE001 – best-effort storage
            print(f"[memory-warning] {e}", file=sys.stderr)


if __name__ == "__main__":
    asyncio.run(chat())
